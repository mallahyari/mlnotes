{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp neural_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Search Engine with Transformers\n",
    "\n",
    "> This tutorial demonstrates how to create a search engine with transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram below shows the architecture of the system:\n",
    "<!-- <img src=\"images/semantic_search_diagram.png\" width=\"600\" height=\"500\" /> -->\n",
    "\n",
    "<img src=\"images/semantic_search_diagram.png\" width=\"600\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class FaissNeuralSearch:\n",
    "    \"\"\" This class represents a neural search that uses faiss as the index for search. \"\"\"\n",
    "    \n",
    "    def __init__(self, model, corpus):\n",
    "        self.model = model\n",
    "        # self.model.to(torch.device('cpu'))\n",
    "        self.corpus = corpus\n",
    "    \n",
    "    \n",
    "    def embed_corpus(self):\n",
    "        \"\"\" convert documents into embeddings. \"\"\"\n",
    "        self.corpus_embeddings = self.model.encode(self.corpus, show_progress_bar=False)\n",
    "        \n",
    "    \n",
    "    def convert_to_float32(self):\n",
    "        \"\"\" Convert the data type of the embeddings into float32. \"\"\"\n",
    "        self.corpus_embeddings = np.array([embedding for embedding in self.corpus_embeddings]).astype(\"float32\")\n",
    "    \n",
    "    \n",
    "    def build_index(self):\n",
    "        \"\"\" Build the index, and add document embeddings into the index. \"\"\"\n",
    "        self.index = faiss.IndexFlatL2(self.corpus_embeddings.shape[1])\n",
    "        self.index.add(self.corpus_embeddings)\n",
    "        \n",
    "    \n",
    "    def search(self, query, top_k):\n",
    "        \"\"\" Search the index and returns the top-k most similar document ids. \"\"\"\n",
    "        query_embedding = self.model.encode([query])\n",
    "        distances, ids = self.index.search(np.array(query_embedding), k=top_k)\n",
    "        return distances, ids\n",
    "    \n",
    "    \n",
    "    def show_results(self, ids):\n",
    "        \"\"\" Prints the most similar documents. \"\"\"\n",
    "        for i in range(len(ids[0])):\n",
    "            print(f\"----------------------------------- Similar document {i + 1} -------------------------------------------\")\n",
    "            print(self.corpus[ids[0][i]])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# show_doc(FaissNeuralSearch.embed_corpus)\n",
    "\n",
    "# show_doc(FaissNeuralSearch.convert_to_float32)\n",
    "\n",
    "# show_doc(FaissNeuralSearch.build_index)\n",
    "\n",
    "# show_doc(FaissNeuralSearch.search)\n",
    "\n",
    "# show_doc(FaissNeuralSearch.show_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Collect a dataset\n",
    "I used a dataset that is about startups. Dataset is in json format and each record includes the name, a paragraph describing the company, the location and a picture. The dataset is available at [this link](https://storage.googleapis.com/generall-shared-data/startups_demo.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>images</th>\n",
       "      <th>alt</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SaferCodes</td>\n",
       "      <td>https://safer.codes/img/brand/logo-icon.png</td>\n",
       "      <td>SaferCodes Logo QR codes generator system form...</td>\n",
       "      <td>QR codes systems for COVID-19.\\nSimple tools f...</td>\n",
       "      <td>https://safer.codes</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human Practice</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/startups...</td>\n",
       "      <td>Human Practice -  health care information tech...</td>\n",
       "      <td>Point-of-care word of mouth\\nPreferral is a mo...</td>\n",
       "      <td>http://humanpractice.com</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StyleSeek</td>\n",
       "      <td>https://d1qb2nb5cznatu.cloudfront.net/startups...</td>\n",
       "      <td>StyleSeek -  e-commerce fashion mass customiza...</td>\n",
       "      <td>Personalized e-commerce for lifestyle products...</td>\n",
       "      <td>http://styleseek.com</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                             images  \\\n",
       "0      SaferCodes        https://safer.codes/img/brand/logo-icon.png   \n",
       "1  Human Practice  https://d1qb2nb5cznatu.cloudfront.net/startups...   \n",
       "2       StyleSeek  https://d1qb2nb5cznatu.cloudfront.net/startups...   \n",
       "\n",
       "                                                 alt  \\\n",
       "0  SaferCodes Logo QR codes generator system form...   \n",
       "1  Human Practice -  health care information tech...   \n",
       "2  StyleSeek -  e-commerce fashion mass customiza...   \n",
       "\n",
       "                                         description  \\\n",
       "0  QR codes systems for COVID-19.\\nSimple tools f...   \n",
       "1  Point-of-care word of mouth\\nPreferral is a mo...   \n",
       "2  Personalized e-commerce for lifestyle products...   \n",
       "\n",
       "                       link     city  \n",
       "0       https://safer.codes  Chicago  \n",
       "1  http://humanpractice.com  Chicago  \n",
       "2      http://styleseek.com  Chicago  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"https://storage.googleapis.com/generall-shared-data/startups_demo.json\", lines=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only implement a search mechanism on the `description` column, i.e. we search and find similar companies based on the similarity of the *search query* and *descriptions*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 40474\n"
     ]
    }
   ],
   "source": [
    "corpus = df.description.tolist()\n",
    "print(f\"Total number of documents: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Depending on the quality of the documents, we may need to perform some preprocessing such as removing special characters, digits, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create dense vectors of documents (i.e. document embeddings).\n",
    "We need to have an embedding model to create embeddings of our text documents. We use a pretrained language model from the [Sentence Transformers](https://www.sbert.net/docs/pretrained_models.html), specifically we utilize `all-distilroberta-v1` model as it works very well for semantic search applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model. You can set the device to `cpu` if don't have access to `gpu`.\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1', device='cuda')\n",
    "\n",
    "# convert documents into embeddings\n",
    "corpus_embeddings = model.encode(corpus, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Store the embeddings or index the embeddings\n",
    "In order to be able to perform search and find documents, we need to store document embeddings in a document store. In other words, we have to `index` them. There are several different ways to do that, nevertheless, I work with Faiss for now.\n",
    "Faiss allows us to search through billions of vectors very efficiently. For complete information about Faiss, please check their [wiki](https://github.com/facebookresearch/faiss/wiki) page or read their [paper](https://arxiv.org/abs/1702.08734).\n",
    "\n",
    "Faiss is built around the `Index` object, which contains searchable vectors. Faiss handles collections of vectors of a fixed dimensionality `d`, typically a few 10s to 100s. \n",
    "\n",
    "> *Faiss uses only 32-bit floating point matrices. This means we will have to change the data type of the input before building the index.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40474, 768)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert the data type of the embeddings into float32.\n",
    "corpus_embeddings = np.array([embedding for embedding in corpus_embeddings]).astype(\"float32\")\n",
    "corpus_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the index. Shape of embeddings is (40474, 768), so we set the dimension of index to 768.\n",
    "index = faiss.IndexFlatL2(corpus_embeddings.shape[1])\n",
    "\n",
    "# Add the document vectors into the index\n",
    "index.add(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the search query\n",
    "Before we search for a query, we must convert the search query into an embedding using the same model we used for document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"smart devices\"\n",
    "\n",
    "# Embed the query\n",
    "query_embedding = model.encode([search_query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8278387 0.8530587 0.9144668 0.9390534 0.9465257]] [[36977  6544  2374 33638 40249]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We're interested in top-5 most similar documents\n",
    "top_k = 5\n",
    "\n",
    "# Search function returns two arrays, Distances of the nearest neighbors with shape (n, k), and Labels/ids of the nearest neighbors with shape (n, k).\n",
    "distances, ids = index.search(np.array(query_embedding), k=top_k)\n",
    "print(distances, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Display the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- Similar document 1 -------------------------------------------\n",
      "smartphone hardware possibilities\n",
      "iPhone apps\n",
      "\n",
      "----------------------------------- Similar document 2 -------------------------------------------\n",
      "Smart sports products\n",
      "\n",
      "----------------------------------- Similar document 3 -------------------------------------------\n",
      "Inventing and manufacturing wearable and smart home products\n",
      "Wearable products that utilize sensor technology and smart home devices.\n",
      "\n",
      "----------------------------------- Similar document 4 -------------------------------------------\n",
      "Smart sports equipment\n",
      "Responsive Sports makes smart sports equipment, for example:\n",
      "IPunch combat gloves that track punch impact, speed and type. The gloves send data over Bluetooth to a smart phone or tablet and upload stats to the web, allowing users to track their progress, take ...\n",
      "\n",
      "----------------------------------- Similar document 5 -------------------------------------------\n",
      "Internet of Things for Research\n",
      "Developing a range of connected devices to make data collection for research easier.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ids[0])):\n",
    "    print(f\"----------------------------------- Similar document {i + 1} -------------------------------------------\")\n",
    "    print(corpus[ids[0][i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "So far, we have implemented a search engine using Faiss fairly simply. However, There are several directions for improvement. \n",
    "- Firstly, `IndexFlatL2` index that we used could be slow for very large datasets as it scales linearly with the number of indexed vectors. That said, Faiss provides [fast indexes](https://github.com/facebookresearch/faiss/wiki/Faster-search).\n",
    "- We can enhance the quality of the embeddings by using a domain specific pretrained model, which could result in better and more accuarate search results.\n",
    "- Is it possible to dynamically exclude vectors based on some criterion? What I mean is, what if we would like to search our documents based on some filters, for instance, only search among the companies that are in a specific city. In these cases, there is no easy solution if we want to make use of Faiss index. Therefore, what is the solution? The answer is to apply other approaches. These approaches are, to name a few:\n",
    "     - [Haystack](https://haystack.deepset.ai/overview/intro): An open-source framework for building search systems that work intelligently over large document collections.\n",
    "     - [Qdrant](https://github.com/qdrant/qdrant): A Vector Search Engine for the next generation of AI applications.\n",
    "     - [Weaviate](https://github.com/semi-technologies/weaviate): Weaviate is a cloud-native, modular, real-time vector search engine\n",
    "     \n",
    "I will create several other examples using these packages and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
