---

title: How to convert pdf documents into a question answering system


keywords: fastai
sidebar: home_sidebar

summary: "This tutorial implements how to create a question answering system on pdf documents."
description: "This tutorial implements how to create a question answering system on pdf documents."
nb_path: "01_qa_on_pdf.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_qa_on_pdf.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO - haystack.modeling.model.optimization -  apex not found, won&#39;t use it. See https://nvidia.github.io/apex/
ERROR - root -  Failed to import &#39;magic&#39; (from &#39;python-magic&#39; and &#39;python-magic-bin&#39; on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The diagram below shows the architecture of the system:
<!-- <img src="images/semantic_search_diagram.png" width="600" height="500" /> --></p>
<p>{% include image.html width="600" height="500" max-width="600" file="/mlnotes/images/semantic_search_diagram.png" %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># doc_pdf = converter.convert(file_path=&quot;data/git_datasheet.pdf&quot;, meta=None)[0]</span>

<span class="n">all_docs</span> <span class="o">=</span> <span class="n">convert_files_to_docs</span><span class="p">(</span><span class="n">dir_path</span><span class="o">=</span><span class="n">PDF_DIR_PATH</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/mehdi/environments/mlnotes/lib/python3.8/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)
  return torch._C._cuda_getDeviceCount() &gt; 0
pdftotext version 0.86.1
Copyright 2005-2020 The Poppler Developers - http://poppler.freedesktop.org
Copyright 1996-2011 Glyph &amp; Cog, LLC
INFO - haystack.utils.preprocessing -  Converting data/git_datasheet.pdf
INFO - haystack.utils.preprocessing -  Converting data/ml_interview.pdf
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-1:-Convert-pdfs-into-text">Step 1: Convert pdfs into text<a class="anchor-link" href="#Step-1:-Convert-pdfs-into-text"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text_document</span> <span class="o">=</span> <span class="n">all_docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">text_document</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;Document: {&#39;content&#39;: &#39;Git and Github\nDatasheet\nINDEX\n1. Introduction\n1.1 What is Git\n1.2 Why Git\n1.3 Features of Git\n1.4 What is Github\n\n2. Configuring Git for the first time\n3. General Git Features\n2.1 Initializing Git\n2.2 Staging files\n2.3 Making a commit\n2.4 Status of files and log\n\nhttps://www.linkedin.com/in/durgesh-mahajan99bab0212/\n\ndurgeshmahajan1722@gmail.com\n\nhttps://github.com/durgeshm01722\n\n@durgeshm01722\n\x0c4. Git Help\n5. Git Branching\n5.1 Making a new Git Branch\n5.2 Checking all available Branches\n5.3 Switching to other Branches\n5.4 Making a new branch and directly switching to it\n5.5 Deleting a Branch\n5.6 Merging two Branches\n\n6. Working with Github\n6.1 Push local repo to GitHub\n6.2 Pull local repo from GitHub\n6.3 Pull branch from GitHub\n6.4 Push branch to GitHub\n\n7. Git Undo\n7.1 Git Revert\n7.2 Git Reset\n7.3 Git Amend\n\x0cWhat is Git :•\n•\n•\n•\n\nGit is a version control system.\nGit helps you keep track of code changes.\nGit is used to collaborate on code.\nGit and GitHub are different things.\n\nWhy Git :•\n•\n•\n•\n\nOver 70% of developers use Git!\nDevelopers can work together from anywhere in the world.\nDevelopers can see the full history of the project.\nDevelopers can revert to earlier versions of a project.\n\nFeatures of Git :•\n•\n•\n•\n•\n•\n\nWhen a file is changed, added or deleted, it is considered\nmodified\nYou select the modified files you want to Stage\nThe Staged files are Committed, which prompts Git to store a\npermanent snapshot of the files\nGit allows you to see the full history of every commit.\nYou can revert back to any previous commit.\nGit does not store a separate copy of every file in every\ncommit, but keeps track of changes made in each commit!\n\nWhat is GitHub :•\n•\n•\n\nGit is not the same as GitHub.\nGitHub makes tools that use Git.\nGitHub is the largest host of source code in the world, and has\nbeen owned by Microsoft since 2018.\n\x0cConfiguring git for the first time :$ git config --global user.name “&lt;Enter your username here&gt;”\n$ git config --global user.email “&lt;Enter your email here&gt;”\n\nGeneral Git Features :Initializing Git :$ git init\n\nGit now knows that it should watch the folder you initiated it\non. Git creates a hidden folder to keep track of changes.\n\nStaging files/Adding files to Git repo :Staged files are files that are ready to be committed to the\nrepository you are working on.\nWhen you first add files to an empty repository, they are all\nuntracked. To get Git to track them, you need to stage them, or add\nthem to the staging environment.\n$ git add &lt;filename with extension&gt;\n\nStaging all files in a folder :$ git add --all\n\nOR\n$ git add -A\n\x0cMaking a Commit :Adding commits keep track of our progress and changes as we\nwork. Git considers each commit change point or &#34;save point&#34;. It is a\npoint in the project you can go back to if you find a bug, or want to\nmake a change.\nWhen we commit, we should always include a message.\n$ git commit -m “&lt;Enter your message here&gt;”\n\nGit Commit without Stage :Sometimes, when you make small changes, using the staging\nenvironment seems like a waste of time. It is possible to commit\nchanges directly, skipping the staging environment.\n$ git commit -a -m “&lt;Enter your message here&gt;”\n\nStatus of files and log :$ git status\n\nFile status in a more compact way :$ git status --short\n\nLog of a file :Log is used to view the history of commits for a repo.\n$ git log\n$ git log --oneline\n\x0cGit Help :If you are having trouble remembering commands or options\nfor commands, you can use Git help.\nSee all the available options for the specific command $ git &lt;command&gt; -help\n\nSee all possible commands $ git help --all\n\nIf you find yourself stuck in the list view, SHIFT + G to jump the\nend of the list, then q to exit the view.\n\nGit Branching :In Git, a branch is a new/separate version of the main repository.\nBranches allow you to work on different parts of a project without\nimpacting the main branch. When the work is complete, a branch can be\nmerged with the main project.\nWe can even switch between branches and work on different\nprojects without them interfering with each other.\n\nMaking a new Git Branch :$ git branch &lt;name of branch&gt;\n\nChecking all available Branches :$ git branch\n\x0cSwitching to other Branches :$ git checkout &lt;branch name&gt;\n\nMaking a new branch and directly switching to\nit :$ git checkout -b &lt;branch name&gt;\n\nDeleting a Branch :$ git branch -d &lt;branch name&gt;\n\nMerging two Branches :It’s preferred to change/switch to master branch before any branch\nneeds to be merged with it.\n$ git merge &lt;branch name&gt;\n\nThis will merge the specified branch with our master branch.\n\x0cWorking with Github :-\n\n+\n\nCreate a github account to create your remote repositories. Now,\ncreate a new repo where we will be uploading our files from local repo.\n\nNote - Local repository (repo.) means the repo. which is on our system\nwhereas, remote repo. means the one which is on other remote system/server,\nfor eg. - GitHub, GitLab, Bitbucket, etc.\n\x0cPush local repo to GitHub :-\n\n+\n\nCopy the url or the link of the repo that we just created. As an\nexample, it should look like this - https://github.com/durgeshm01722\n/example.git\nPaste the copied url in the below git command.\n$ git remote add origin &lt;paste copied URL here&gt;\n\n‘git remote add origin &lt;URL&gt;’ specifies that we are adding a remote\nrepository, with the specified URL, as an origin to our local Git repo.\nFinally, pushing our master branch to the origin URL (remote repo)\nand set it as the default remote branch.\n$ git push --set-upstream origin master\n\nGo back into GitHub and see that the repository has been updated.\n\nPushing local repo to github after doing the above\nprocess at least once :First commit all the changes. Then push all the changes to our\nremote origin i.e. remote repo on github.\n$ git push origin\n\nPull local repo from GitHub :Git pull is used to pull all changes from a remote repository into the\nbranch we are working on. It is a combination of fetch and merge. Use it\nto update your local Git.\n\n$ git pull origin\n\x0cPull branch from GitHub :-\n\n+\n\nFirst, check which branches we have and where are we working at\nthe moment by ‘git branch’ command. Since we do not have the new\nbranch on out local Git which is to be pulled from the Github. So, to see all\nlocal and remote branches, use $ git branch -a\n\nFor viewing only remote branches :$ git branch -r\n\nNow, the new branch is seen in the console but it is not available on\nour local repo. So, let’s check it out using ‘git checkout &lt;branch name&gt;’.\nNow run ‘git pull’ to pull that branch on our local repo. We can now check\nthe available branches using ‘git branch’.\n\nPush branch to GitHub :First, let’s create a new local branch which we will be pushing to\nGithub. Enter the command as ‘git checkout -b &lt;branch name&gt;’. You can\ncheck the status of the files in this current branch using ‘git status’.\nCommit all the uncommitted changes for all the files in this branch using\n‘git commit -a -m “&lt;Message&gt;” ’. Now push this branch from our local\nrepo to Github using ‘git push origin &lt;branch name&gt;’.\n\nGit clone from GitHub :We can clone a forked repo from Github on our local repo. A clone is\na full copy of a repository, including all logging and versions of files. Move\nback to the original repository, and click the green &#34;Code&#34; button to get\nthe URL to clone. Copy the URL.\n\x0c+\nNow in the git bash, enter the following command to clone the\ncopied repo onto your local machine $ git clone &lt;copied URL&gt;\n\nTo specify a specific folder to clone to, add the name of the folder\nafter the repository URL, like this $ git clone &lt;copied URL&gt; &lt;folder name&gt;\n\x0cGit Undo :Git Revert :‘revert’ is the command we use when we want to take a previous\ncommit and add it as a new commit, keeping the log intact. First thing, we\nneed to find the point we want to return to. To do that, we need to go\nthrough the log. To avoid the very long log list, use the --oneline option\nwhich gives just one line per commit showing –\ni. The first seven characters of the commit hash\nii. The commit message\n\nGit Revert HEAD :We revert the latest commit using ‘git revert HEAD’ (revert the latest\nchange, and then commit). By adding the option --no-edit, we can skip the\ncommit message editor (getting the default revert message).\n$ git revert HEAD --no-edit\n\nGit Revert to any commit :To revert to earlier commits, use ‘git revert HEAD~x’ (x being a\nnumber. 1 going back one more, 2 going back two more, etc.)\n\nGit Reset :‘reset’ is the command we use when we want to move the repository\nback to a previous commit, discarding any changes made after that commit.\nFirst, get the seven characters of the commit hash from the log for the\ncommit that you want to go back for. Then we reset our repository back to\nthat specific commit using ‘git reset commithash’ (commithash being the first\n7 characters of the commit hash we found in the log).\n\x0c$ git reset &lt;commithash&gt;\n\nGit Undo Reset :Even though the commits are no longer showing up in the log, it is not\nremoved from Git. If we know the commit hash, we can reset to it using ‘git\nreset &lt;commithash&gt;’.\n\nGit Amend :commit --amend is used to modify the most recent commit. It combines\nchanges in the staging environment with the latest commit, and creates a\nnew commit. This new commit replaces the latest commit entirely.\nOne of the simplest things you can do with --amend is to change a\ncommit message.\n$ git commit --amend -m “&lt;Commit Message&gt;”\n\nUsing this, the previous commit is replaced with our amended one.\n\nGit Amend Files :Adding files with --amend works the same way as above. Just add them\nto the staging environment before committing.\n\x0cThanks for Reading!!!\nDo share your valuable feedback in the comments if\nyou found this content helpful.\nYou can also email your feedback or suggestions on my\nemail - durgeshmahajan1722@gmail.com\n&#39;, &#39;content_type&#39;: &#39;text&#39;, &#39;score&#39;: None, &#39;meta&#39;: {&#39;name&#39;: &#39;git_datasheet.pdf&#39;}, &#39;embedding&#39;: None, &#39;id&#39;: &#39;c90abc866220797c75b05660c2ec1292&#39;}&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">PreProcessor</span><span class="p">(</span>
    <span class="n">clean_empty_lines</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">clean_whitespace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">clean_header_footer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">split_by</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span>
    <span class="n">split_length</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">split_respect_sentence_boundary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">all_docs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_docs_input: 1</span><span class="se">\n</span><span class="s2">n_docs_output: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|█████████████████████████████████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 22.14docs/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>n_docs_input: 1
n_docs_output: 66
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">docs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;Document: {&#39;content&#39;: &#39;Git Undo\n7.1 Git Revert\n7.2 Git Reset\n7.3 Git Amend\n\nWhat is Git :•\n•\n•\n•\n\nGit is a version control system. Git helps you keep track of code changes. Git is used to collaborate on code. Git and GitHub are different things. Why Git :•\n•\n•\n•\n\nOver 70% of developers use Git! Developers can work together from anywhere in the world. Developers can see the full history of the project. Developers can revert to earlier versions of a project.&#39;, &#39;content_type&#39;: &#39;text&#39;, &#39;score&#39;: None, &#39;meta&#39;: {&#39;name&#39;: &#39;git_datasheet.pdf&#39;, &#39;_split_id&#39;: 1}, &#39;embedding&#39;: None, &#39;id&#39;: &#39;57defc05b314caa7b408a31df3b66758&#39;}&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">haystack.document_stores</span> <span class="kn">import</span> <span class="n">ElasticsearchDocumentStore</span>

<span class="n">document_store</span> <span class="o">=</span> <span class="n">ElasticsearchDocumentStore</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s2">&quot;localhost&quot;</span><span class="p">,</span> <span class="n">username</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="s2">&quot;qa_index&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">document_store</span><span class="o">.</span><span class="n">write_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">haystack.nodes</span> <span class="kn">import</span> <span class="n">BM25Retriever</span>

<span class="n">retriever</span> <span class="o">=</span> <span class="n">BM25Retriever</span><span class="p">(</span><span class="n">document_store</span><span class="o">=</span><span class="n">document_store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">haystack.nodes</span> <span class="kn">import</span> <span class="n">FARMReader</span><span class="p">,</span> <span class="n">TransformersReader</span>

<span class="n">reader</span> <span class="o">=</span> <span class="n">FARMReader</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="o">=</span><span class="s2">&quot;deepset/roberta-base-squad2&quot;</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO - haystack.modeling.utils -  Using devices: CPU
INFO - haystack.modeling.utils -  Number of GPUs: 0
INFO - haystack.modeling.model.language_model -  LOADING MODEL
INFO - haystack.modeling.model.language_model -  =============
INFO - haystack.modeling.model.language_model -  Could not find deepset/roberta-base-squad2 locally.
INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...
INFO - haystack.modeling.model.language_model -  Loaded deepset/roberta-base-squad2
INFO - haystack.modeling.utils -  Using devices: CPU
INFO - haystack.modeling.utils -  Number of GPUs: 0
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO - haystack.modeling.infer -  Got ya 19 parallel workers to do inference ...
INFO - haystack.modeling.infer -   0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0  
INFO - haystack.modeling.infer -  /w\   /w\   /w\   /w\   /w\   /w\   /w\   /|\  /w\   /w\   /w\   /w\   /w\   /w\   /|\  /w\   /|\  /|\  /|\
INFO - haystack.modeling.infer -  /&#39;\   / \   /&#39;\   /&#39;\   / \   / \   /&#39;\   /&#39;\   /&#39;\   /&#39;\   /&#39;\   /&#39;\   / \   /&#39;\   /&#39;\   / \   /&#39;\   /&#39;\   /&#39;\ 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">haystack.pipelines</span> <span class="kn">import</span> <span class="n">ExtractiveQAPipeline</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">ExtractiveQAPipeline</span><span class="p">(</span><span class="n">reader</span><span class="p">,</span> <span class="n">retriever</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;how to merge branches&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Retriever&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="s2">&quot;Reader&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">}}</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  3.83 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.43 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.10 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  5.31 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.28 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.45 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.68 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.44 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.83 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.93 Batches/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_answers</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="s2">&quot;minimum&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Query: how to merge branches
Answers:
[   {   &#39;answer&#39;: &#39;When the work is complete, a branch can be\n&#39;
                  &#39;merged with the main project&#39;,
        &#39;context&#39;: &#39;ou to work on different parts of a project without\n&#39;
                   &#39;impacting the main branch. When the work is complete, a &#39;
                   &#39;branch can be\n&#39;
                   &#39;merged with the main project.&#39;},
    {   &#39;answer&#39;: &#39;Git Branch&#39;,
        &#39;context&#39;: &#39;erent\n&#39;
                   &#39;projects without them interfering with each other. Making &#39;
                   &#39;a new Git Branch :$ git branch &lt;name of branch&gt;\n&#39;
                   &#39;\n&#39;
                   &#39;Checking all available Branches :$ gi&#39;},
    {   &#39;answer&#39;: &#39;+&#39;,
        &#39;context&#39;: &#39; it\n&#39;
                   &#39;to update your local Git. $ git pull origin\n&#39;
                   &#39;\n&#39;
                   &#39;Pull branch from GitHub :-\n&#39;
                   &#39;\n&#39;
                   &#39;+\n&#39;
                   &#39;\n&#39;
                   &#39;First, check which branches we have and where are we &#39;
                   &#39;working at\n&#39;
                   &#39;the mo&#39;},
    {   &#39;answer&#39;: &#39;Merging two Branches&#39;,
        &#39;context&#39;: &#39;ew branch and directly switching to it\n&#39;
                   &#39;5.5 Deleting a Branch\n&#39;
                   &#39;5.6 Merging two Branches\n&#39;
                   &#39;\n&#39;
                   &#39;6. Working with Github\n&#39;
                   &#39;6.1 Push local repo to GitHub\n&#39;
                   &#39;6.2 Pull l&#39;},
    {   &#39;answer&#39;: &#39;boosting to a “bucket of models&#39;,
        &#39;context&#39;: &#39;ould list some examples of ensemble methods, from bagging &#39;
                   &#39;to\n&#39;
                   &#39;boosting to a “bucket of models” method and demonstrate &#39;
                   &#39;how they\n&#39;
                   &#39;could increase predictiv&#39;}]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;how totrade off bias as vs variance&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Retriever&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="s2">&quot;Reader&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">}}</span>
<span class="p">)</span>
<span class="n">print_answers</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="s2">&quot;minimum&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  7.67 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.15 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.20 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.11 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.16 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  8.85 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.15 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.45 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.81 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.45 Batches/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Query: how totrade off bias as vs variance
Answers:
[   {   &#39;answer&#39;: &#39;Bias-Variance Tradeoff&#39;,
        &#39;context&#39;: &#39;- What’s the trade-off between bias and variance? More &#39;
                   &#39;reading: Bias-Variance Tradeoff (Wikipedia)\n&#39;
                   &#39;Bias is error due to erroneous or overly simplistic&#39;},
    {   &#39;answer&#39;: &#39;Keep the model simpler: reduce variance by taking into &#39;
                  &#39;account\n&#39;
                  &#39;fewer variables and parameters&#39;,
        &#39;context&#39;: &#39;ds to avoid overfitting:\n&#39;
                   &#39;\n&#39;
                   &#39;1- Keep the model simpler: reduce variance by taking into &#39;
                   &#39;account\n&#39;
                   &#39;fewer variables and parameters, thereby removing some of &#39;
                   &#39;t&#39;},
    {   &#39;answer&#39;: &#39;you’ll have to tradeoff bias and variance&#39;,
        &#39;context&#39;: &#39;in order to get the optimally reduced\n&#39;
                   &#39;amount of error, you’ll have to tradeoff bias and &#39;
                   &#39;variance. You don’t\n&#39;
                   &#39;want either high bias or high variance in &#39;},
    {   &#39;answer&#39;: &#39;The bias-variance decomposition essentially decomposes the &#39;
                  &#39;learning\n&#39;
                  &#39;error from any algorithm by adding the bias, the variance &#39;
                  &#39;and a bit of\n&#39;
                  &#39;irreducible error due to noise in the underlying dataset&#39;,
        &#39;context&#39;: &#39; The bias-variance decomposition essentially decomposes &#39;
                   &#39;the learning\n&#39;
                   &#39;error from any algorithm by adding the bias, the variance &#39;
                   &#39;and a bit of\n&#39;
                   &#39;irreducible error due to noise in the underlying dataset&#39;},
    {   &#39;answer&#39;: &#39;Mathematically, it’s expressed as the true positive rate of &#39;
                  &#39;a condition\n&#39;
                  &#39;sample divided by the sum of the false positive rate of the &#39;
                  &#39;population\n&#39;
                  &#39;and the true positive rate of a condition&#39;,
        &#39;context&#39;: &#39;Mathematically, it’s expressed as the true positive rate &#39;
                   &#39;of a condition\n&#39;
                   &#39;sample divided by the sum of the false positive rate of &#39;
                   &#39;the population\n&#39;
                   &#39;and the true positive rate of a condition&#39;}]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Usine-Embedding-models">Usine Embedding models<a class="anchor-link" href="#Usine-Embedding-models"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='dimension of the embedding model and document store must be the same' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># em_document_store.delete_index(&quot;em_qa_index&quot;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">em_document_store</span> <span class="o">=</span> <span class="n">ElasticsearchDocumentStore</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s2">&quot;localhost&quot;</span><span class="p">,</span> <span class="n">username</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="s2">&quot;em_qa_index&quot;</span><span class="p">,</span> <span class="n">similarity</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">384</span><span class="p">)</span>
<span class="c1"># em_document_store.delete_documents()</span>
<span class="n">em_document_store</span><span class="o">.</span><span class="n">write_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">haystack.nodes</span> <span class="kn">import</span> <span class="n">EmbeddingRetriever</span>
<span class="n">em_retriever</span> <span class="o">=</span> <span class="n">EmbeddingRetriever</span><span class="p">(</span>
    <span class="n">document_store</span><span class="o">=</span><span class="n">em_document_store</span><span class="p">,</span>
    <span class="n">embedding_model</span><span class="o">=</span><span class="s2">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span><span class="p">,</span>
    <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">scale_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO - haystack.modeling.utils -  Using devices: CPU
INFO - haystack.modeling.utils -  Number of GPUs: 0
INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model sentence-transformers/all-MiniLM-L6-v2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">em_document_store</span><span class="o">.</span><span class="n">update_embeddings</span><span class="p">(</span><span class="n">em_retriever</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 66 docs ...
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">em_retriever</span><span class="o">.</span><span class="n">embedding_encoder</span><span class="o">.</span><span class="n">embedding_model</span><span class="o">.</span><span class="n">get_sentence_embedding_dimension</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>384</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">em_pipe</span> <span class="o">=</span> <span class="n">ExtractiveQAPipeline</span><span class="p">(</span><span class="n">reader</span><span class="p">,</span> <span class="n">em_retriever</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;how to merge two branches&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">em_pipe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Retriever&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="s2">&quot;Reader&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">}}</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  7.18 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  5.68 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.03 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.12 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.78 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.08 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.52 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.30 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.78 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.37 Batches/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_answers</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="s2">&quot;minimum&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Query: how to merge two branches
Answers:
[   {   &#39;answer&#39;: &#39;It’s preferred to change/switch to master branch&#39;,
        &#39;context&#39;: &#39;git branch -d &lt;branch name&gt;\n&#39;
                   &#39;\n&#39;
                   &#39;Merging two Branches :It’s preferred to change/switch to &#39;
                   &#39;master branch before any branch\n&#39;
                   &#39;needs to be merged with it. $ gi&#39;},
    {   &#39;answer&#39;: &#39;When the work is complete, a branch can be\n&#39;
                  &#39;merged with the main project&#39;,
        &#39;context&#39;: &#39;ou to work on different parts of a project without\n&#39;
                   &#39;impacting the main branch. When the work is complete, a &#39;
                   &#39;branch can be\n&#39;
                   &#39;merged with the main project.&#39;},
    {   &#39;answer&#39;: &#39;+&#39;,
        &#39;context&#39;: &#39; it\n&#39;
                   &#39;to update your local Git. $ git pull origin\n&#39;
                   &#39;\n&#39;
                   &#39;Pull branch from GitHub :-\n&#39;
                   &#39;\n&#39;
                   &#39;+\n&#39;
                   &#39;\n&#39;
                   &#39;First, check which branches we have and where are we &#39;
                   &#39;working at\n&#39;
                   &#39;the mo&#39;},
    {   &#39;answer&#39;: &#39;5.6 Merging two Branches\n&#39;
                  &#39;\n&#39;
                  &#39;6. Working with Github\n&#39;
                  &#39;6.1 Push local repo to GitHub\n&#39;
                  &#39;6.2 Pull local repo from GitHub\n&#39;
                  &#39;6.3 Pull branch from GitHub\n&#39;
                  &#39;6.4 Push branch to GitHub\n&#39;
                  &#39;\n&#39;
                  &#39;7.&#39;,
        &#39;context&#39;: &#39;5.6 Merging two Branches\n&#39;
                   &#39;\n&#39;
                   &#39;6. Working with Github\n&#39;
                   &#39;6.1 Push local repo to GitHub\n&#39;
                   &#39;6.2 Pull local repo from GitHub\n&#39;
                   &#39;6.3 Pull branch from GitHub\n&#39;
                   &#39;6.4 Push branch to GitHub\n&#39;
                   &#39;\n&#39;
                   &#39;7.&#39;},
    {   &#39;answer&#39;: &#39;email&#39;,
        &#39;context&#39;: &#39;feedback in the comments if\n&#39;
                   &#39;you found this content helpful. You can also email your &#39;
                   &#39;feedback or suggestions on my\n&#39;
                   &#39;email - durgeshmahajan1722@gmail.com&#39;}]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;how to clone a forked repo&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">em_pipe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Retriever&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="s2">&quot;Reader&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}}</span>
<span class="p">)</span>
<span class="n">print_answers</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  7.84 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.43 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.08 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.11 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.55 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  5.35 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.03 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.78 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.82 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.26 Batches/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Query: how to clone a forked repo
Answers:
[   &lt;Answer {&#39;answer&#39;: &#39;Github on our local repo&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.30540235340595245, &#39;context&#39;: &#39;name&gt;’. Git clone from GitHub :We can clone a forked repo from Github on our local repo. A clone is\na full copy of a repository, including all logging&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 333, &#39;end&#39;: 357}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 63, &#39;end&#39;: 87}], &#39;document_id&#39;: &#39;1974609b6b4a3b3e88bf08872631806c&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 12, &#39;name&#39;: &#39;git_datasheet.pdf&#39;}}&gt;,
    &lt;Answer {&#39;answer&#39;: &#39;&lt;folder name&gt;&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.15925748273730278, &#39;context&#39;: &#39; folder\nafter the repository URL, like this $ git clone &lt;copied URL&gt; &lt;folder name&gt;\n\nGit Undo :Git Revert :‘revert’ is the command we use when we want &#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 256, &#39;end&#39;: 269}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 69, &#39;end&#39;: 82}], &#39;document_id&#39;: &#39;23af4f16ecff716976d8dfc378717491&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 13, &#39;name&#39;: &#39;git_datasheet.pdf&#39;}}&gt;,
    &lt;Answer {&#39;answer&#39;: &#39;Git Branch&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.06454721465706825, &#39;context&#39;: &#39;erent\nprojects without them interfering with each other. Making a new Git Branch :$ git branch &lt;name of branch&gt;\n\nChecking all available Branches :$ gi&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 122, &#39;end&#39;: 132}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 70, &#39;end&#39;: 80}], &#39;document_id&#39;: &#39;ca51e9320124f6972dc7e437cd141729&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 7, &#39;name&#39;: &#39;git_datasheet.pdf&#39;}}&gt;]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;how much data does k-means need&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">em_pipe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Retriever&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">},</span> <span class="s2">&quot;Reader&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">}}</span>
<span class="p">)</span>
<span class="n">print_answers</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  8.25 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.36 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.25 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 11.29 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.46 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.62 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.84 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  9.09 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.40 Batches/s]
Inferencing Samples: 100%|████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 10.45 Batches/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Query: how much data does k-means need
Answers:
[   &lt;Answer {&#39;answer&#39;: &#39;a set of unlabeled points and\na threshold&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.1355515830218792, &#39;context&#39;: &#39;arest neighbor\npart). K-means clustering requires only a set of unlabeled points and\na threshold: the algorithm will take unlabeled points and gradual&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 255, &#39;end&#39;: 296}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 55, &#39;end&#39;: 96}], &#39;document_id&#39;: &#39;c1af22d9cff2a34698de3acc7b697449&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 7, &#39;name&#39;: &#39;ml_interview.pdf&#39;}}&gt;,
    &lt;Answer {&#39;answer&#39;: &#39;immense&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.05257562734186649, &#39;context&#39;: &#39;Spark is the big data\ntool most in demand now, able to handle immense datasets with\nspeed. Be honest if you don’t have experience with the tools\n\ndema&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 62, &#39;end&#39;: 69}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 62, &#39;end&#39;: 69}], &#39;document_id&#39;: &#39;ece5d555846146859441aa08c807a107&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 34, &#39;name&#39;: &#39;ml_interview.pdf&#39;}}&gt;,
    &lt;Answer {&#39;answer&#39;: &#39;knowledge&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.034088036976754665, &#39;context&#39;: &#39;The ideal answer would demonstrate\nknowledge of what drives the business and how your skills could\nrelate. For example, if you were interviewing for m&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 34, &#39;end&#39;: 43}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 34, &#39;end&#39;: 43}], &#39;document_id&#39;: &#39;82d2cda12ee807bc4e871a71444c97a0&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 39, &#39;name&#39;: &#39;ml_interview.pdf&#39;}}&gt;,
    &lt;Answer {&#39;answer&#39;: &#39;recaptcha&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.023469333071261644, &#39;context&#39;: &#39;ods, and your inventiveness if you don’t know the answer. Google is currently using\nrecaptcha to source labeled data on storefronts and traffic signs.&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 590, &#39;end&#39;: 599}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 83, &#39;end&#39;: 92}], &#39;document_id&#39;: &#39;5621287ef36b7dcdfe70319309c58e13&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 45, &#39;name&#39;: &#39;ml_interview.pdf&#39;}}&gt;,
    &lt;Answer {&#39;answer&#39;: &#39;programming principles&#39;, &#39;type&#39;: &#39;extractive&#39;, &#39;score&#39;: 0.01658477447926998, &#39;context&#39;: &#39;hese machine learning interview questions test your knowledge of\nprogramming principles you need to implement machine learning\nprinciples in practice.&#39;, &#39;offsets_in_document&#39;: [{&#39;start&#39;: 227, &#39;end&#39;: 249}], &#39;offsets_in_context&#39;: [{&#39;start&#39;: 64, &#39;end&#39;: 86}], &#39;document_id&#39;: &#39;2d5b06c0d719b1dc15b4bdeb1929312d&#39;, &#39;meta&#39;: {&#39;_split_id&#39;: 32, &#39;name&#39;: &#39;ml_interview.pdf&#39;}}&gt;]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">doc_id</span> <span class="o">=</span> <span class="s2">&quot;1974609b6b4a3b3e88bf08872631806c&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">em_document_store</span><span class="o">.</span><span class="n">get_document_by_id</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>You can
check the status of the files in this current branch using ‘git status’. Commit all the uncommitted changes for all the files in this branch using
‘git commit -a -m “&lt;Message&gt;” ’. Now push this branch from our local
repo to Github using ‘git push origin &lt;branch name&gt;’. Git clone from GitHub :We can clone a forked repo from Github on our local repo. A clone is
a full copy of a repository, including all logging and versions of files. Move
back to the original repository, and click the green &#34;Code&#34; button to get
the URL to clone. Copy the URL.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="n">my_html</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&lt;p&gt;</span><span class="si">{</span><span class="n">text</span><span class="p">[:</span><span class="mi">255</span><span class="p">]</span><span class="si">}</span><span class="s1">&lt;b&gt;</span><span class="si">{</span><span class="n">highlighted_text</span><span class="si">}</span><span class="s1">&lt;/b&gt;</span><span class="si">{</span><span class="n">text</span><span class="p">[</span><span class="mi">296</span><span class="p">:]</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">my_html</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><p>While the mechanisms may seem similar at first, what this really means is that in order for K-Nearest Neighbors to work, you need labeled data you want to classify an unlabeled point into (thus the nearest neighbor part). K-means clustering requires only <b>a set of unlabeled points and a threshold</b>: the algorithm will take unlabeled points and gradually learn how to cluster them into groups by computing the mean of the distance between different points. The critical difference here is that KNN needs labeled points and is thus supervised learning, while k-means doesn’t — and is thus unsupervised learning. Q4- Explain how a ROC curve works.</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">haystack.pipelines</span> <span class="kn">import</span> <span class="n">DocumentSearchPipeline</span>

<span class="n">re_pipe</span> <span class="o">=</span> <span class="n">DocumentSearchPipeline</span><span class="p">(</span><span class="n">retriever</span><span class="o">=</span><span class="n">em_retriever</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;how much data does k-nearest neighbor need&quot;</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">re_pipe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Retriever&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;top_k&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}}</span>
<span class="p">)</span>
<span class="c1"># print_answers(prediction, details=&quot;minimum&quot;)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/mehdi/environments/mlnotes/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.
  warnings.warn(message, category=ElasticsearchDeprecationWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">prediction</span><span class="p">[</span><span class="s2">&quot;documents&quot;</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==============&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>While the
mechanisms may seem similar at first, what this really means is that
in order for K-Nearest Neighbors to work, you need labeled data you
want to classify an unlabeled point into (thus the nearest neighbor
part). K-means clustering requires only a set of unlabeled points and
a threshold: the algorithm will take unlabeled points and gradually
learn how to cluster them into groups by computing the mean of the
distance between different points. The critical difference here is that KNN needs labeled points and is
thus supervised learning, while k-means doesn’t — and is thus unsupervised learning. Q4- Explain how a ROC curve works.
==============
For example, in
order to do classification (a supervised learning task), you’ll need to
first label the data you’ll use to train the model to classify data into
your labeled groups. Unsupervised learning, in contrast, does not
require labeling data explicitly. Q3- How is KNN different from k-means clustering? More reading: How is the k-nearest neighbor algorithm different from
k-means clustering? (Quora)
K-Nearest Neighbors is a supervised classification algorithm, while
k-means clustering is an unsupervised clustering algorithm.
==============
More reading: Kernel method (Wikipedia)
The Kernel trick involves kernel functions that can enable in higherdimension spaces without explicitly calculating the coordinates of
points within that dimension: instead, kernel functions compute the
inner products between the images of all pairs of data in a feature
space. This allows them the very useful attribute of calculating the
coordinates of higher dimensions while being computationally
cheaper than the explicit calculation of said coordinates. Many algorithms can be expressed in terms of inner products. Using the kernel
trick enables us effectively run algorithms in a high-dimensional
space with lower-dimensional data.
==============
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>


